{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90598c91",
   "metadata": {},
   "source": [
    "# 1. Memasukkan Library\n",
    "Langkah pertama untuk melakukan preprocessing adalah mengimport beberapa library python, yaitu :\n",
    "1. Numpy, berfungsi untuk melakukan operasi matematika, manipulasi array, dan analisis data pada Python. \n",
    "2. Matplotlib, berfungsi untuk membuat visualisasi data secara grafis.\n",
    "3. Pandas, berfungsi untuk memanipulasi dan menganalisis data dalam format tabel atau dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae6d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f8c70",
   "metadata": {},
   "source": [
    "# 2. Import Dataset\n",
    "Setelah memasukkan library, langkah selanjutnya adalah memasukkan file dataset yang ingin digunakan dengan menggunakan fungsi 'pd.read' yang dimiliki oleh library Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc22ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv('latihan_interval_lari.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4ee20",
   "metadata": {},
   "source": [
    "## 2.1. Tampilkan Data yang Telah di masukkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b85c419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Umur</th>\n",
       "      <th>Waktu(s)</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adi</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ditya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adith</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agung</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akhmad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2452.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ardian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arifianto</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Atinna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bektiningsih</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2531.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bondan</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Edi</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Nama  Umur  Waktu(s) Target\n",
       "0            Adi  19.0    2322.0    Yes\n",
       "1          Ditya   NaN    2622.0    Yes\n",
       "2          Adith  18.0    2321.0     No\n",
       "3          Agung  18.0    2312.0    Yes\n",
       "4         Akhmad   NaN    2452.0     No\n",
       "5         Ardian  19.0       NaN     No\n",
       "6      Arifianto  19.0    2152.0    Yes\n",
       "7         Atinna   NaN    2362.0     No\n",
       "8   Bektiningsih  18.0    2531.0    Yes\n",
       "9         Bondan  18.0    2351.0    Yes\n",
       "10           Edi  19.0       NaN     No"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4871c51",
   "metadata": {},
   "source": [
    "Diketahui ketika menampilkan data dari dataset, terdapat Missing Value dengan disimbolkan isian 'NaN'. Agar Missing Value dapat diketahui jumlahnya, maka langkah selanjutnya adalah memasukan perintah untuk menghitung jumlah Missing Value setiap atributnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7faee137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nama        0\n",
       "Umur        3\n",
       "Waktu(s)    2\n",
       "Target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba7ae1",
   "metadata": {},
   "source": [
    "Rincian diatas menyebutkan bahwa data dengan Atribut 'Umur' mengalami Missing Value sebanyak 3 record dan data dengan Atribut 'Waktu(s)' mengalami Missing Value sebanyak 2 record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f74237",
   "metadata": {},
   "source": [
    "## 2.2. Bagi Data dengan Dua Variable\n",
    "Selanjutnya membagi data dengan memasukkanya kedalam dua variable. Variable 'x' untuk data yang berupa atribut, dan variable 'y' untuk data yang berupa class/label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c9e44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataFrame.iloc[:, :-1].values\n",
    "y = dataFrame.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba4445",
   "metadata": {},
   "source": [
    "## 2.3. Tampilkan Data yang Telah dibagi dengan Dua Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c96728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Adi' 19.0 2322.0]\n",
      " ['Ditya' nan 2622.0]\n",
      " ['Adith' 18.0 2321.0]\n",
      " ['Agung' 18.0 2312.0]\n",
      " ['Akhmad' nan 2452.0]\n",
      " ['Ardian' 19.0 nan]\n",
      " ['Arifianto' 19.0 2152.0]\n",
      " ['Atinna' nan 2362.0]\n",
      " ['Bektiningsih' 18.0 2531.0]\n",
      " ['Bondan' 18.0 2351.0]\n",
      " ['Edi' 19.0 nan]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84ff84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0030f0a",
   "metadata": {},
   "source": [
    "# 3. Melakukan Data Cleaning\n",
    "Diketahui proses sebelumnya terdapat data yang mengalami Missing Value, sehingga langkah selanjutnya data harus diperbaiki dengan melakukan Data Cleaning atau pembersihan data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb80c2",
   "metadata": {},
   "source": [
    "Pembersihan data dapat dilakukan dengan memanggil library 'sklearn' dengan mengakses folder 'impute' dan memasukkan fungsi 'SimpleImputer'. Metode yang dilakukan adalah dengan mengambil nilai rata-rata (mean) dari masing-masing atribut yang mengalami Missing Value, lalu selanjutnya data yang kosong sebelumnya akan digantikan dengan nilai mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04287606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x[:, 1:3])\n",
    "x[:, 1:3]= imputer.transform(x[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84989c29",
   "metadata": {},
   "source": [
    "Tampilkan hasil Data Cleaning dengan mencetak variable menampung data yang telah dibuat pada langkah sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c1d8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Adi' 19.0 2322.0]\n",
      " ['Ditya' 18.5 2622.0]\n",
      " ['Adith' 18.0 2321.0]\n",
      " ['Agung' 18.0 2312.0]\n",
      " ['Akhmad' 18.5 2452.0]\n",
      " ['Ardian' 19.0 2380.5555555555557]\n",
      " ['Arifianto' 19.0 2152.0]\n",
      " ['Atinna' 18.5 2362.0]\n",
      " ['Bektiningsih' 18.0 2531.0]\n",
      " ['Bondan' 18.0 2351.0]\n",
      " ['Edi' 19.0 2380.5555555555557]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a82f1b",
   "metadata": {},
   "source": [
    "Sekarang data telah terisi sepenuhnya dan tidak ada data yang mengalami Missing Value. Sehingga data dapat diolah pada proses berikutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a5c7c",
   "metadata": {},
   "source": [
    "# 4. Melakukan Encoding\n",
    "Langkah selanjutnya adalah mengubah data kategorikal/non-numerik(String) kedalam bentuk numerik(Float atau Integer). Hal ini dilakukan agar data dapat diproses oleh mesin. Kegiatan ini dinamakan 'Encoding'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5dd710",
   "metadata": {},
   "source": [
    "## 4.1. Encoding label/class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35b814b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddfb8dc",
   "metadata": {},
   "source": [
    "Code tersebut melakukan encoding pada data label y menggunakan kelas LabelEncoder dari library sklearn.preprocessing. Label encoding adalah proses mengubah nilai-nilai kategori menjadi nilai numerik, sehingga dapat diproses oleh model machine learning.\n",
    "\n",
    "Pertama-tama, dilakukan import kelas LabelEncoder dari library sklearn.preprocessing dengan from sklearn.preprocessing import LabelEncoder.\n",
    "\n",
    "Selanjutnya, objek le dibuat sebagai instance dari kelas LabelEncoder dengan le = LabelEncoder().\n",
    "\n",
    "Kemudian, data label y diubah menjadi nilai numerik dengan menggunakan method fit_transform() dari objek le. Method ini akan mengembalikan array baru yang berisi nilai numerik yang sesuai dengan nilai-nilai kategori pada y. Hasil transformasi disimpan ke variabel y dengan y = le.fit_transform(y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4397e255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da68239",
   "metadata": {},
   "source": [
    "Dengan melakukan encoding pada data label, nilai-nilai kategori akan diubah menjadi nilai numerik yang dapat diproses oleh model machine learning seperti algoritma klasifikasi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0bb5d",
   "metadata": {},
   "source": [
    "## 4.2. Encoding Atribut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87fbfa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[0])], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27bce2",
   "metadata": {},
   "source": [
    "Code tersebut melakukan transformasi data pada satu atau beberapa kolom di dalam suatu dataframe menggunakan kelas ColumnTransformer dan OneHotEncoder dari library sklearn. Objek ct dibuat sebagai instance dari kelas ColumnTransformer dan diatur spesifikasi transformasi yang ingin dilakukan pada data dengan menggunakan OneHotEncoder(). Parameter remainder menunjukkan bahwa kolom-kolom yang tidak diubah oleh OneHotEncoder() akan tetap dipertahankan. Objek ct dapat diterapkan pada data dengan menggunakan method fit_transform()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d8566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ct.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c51a3",
   "metadata": {},
   "source": [
    "Code tersebut melakukan transformasi data pada dataframe x dengan menggunakan objek ct yang telah diatur spesifikasi transformasinya sebelumnya. Method fit_transform() digunakan untuk melakukan transformasi tersebut dan menghasilkan array yang baru. Method toarray() kemudian digunakan untuk mengubah hasil transformasi menjadi array numpy. Hasil transformasi disimpan kembali ke variabel x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb95b7",
   "metadata": {},
   "source": [
    "Cetak data yang telah dilakukan Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8d6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.90000000e+01\n",
      "  2.32200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 0.00000000e+00 1.85000000e+01\n",
      "  2.62200000e+03]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.80000000e+01\n",
      "  2.32100000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.80000000e+01\n",
      "  2.31200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.85000000e+01\n",
      "  2.45200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.90000000e+01\n",
      "  2.38055556e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.90000000e+01\n",
      "  2.15200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.85000000e+01\n",
      "  2.36200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.80000000e+01\n",
      "  2.53100000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 1.80000000e+01\n",
      "  2.35100000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.90000000e+01\n",
      "  2.38055556e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94931a",
   "metadata": {},
   "source": [
    "# 5. Membagi dataset ke dalam training set dan test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2fb4e",
   "metadata": {},
   "source": [
    "Dengan membagi dataset menjadi training set dan test set, kita dapat mengukur kinerja model pada data yang belum pernah dilihat sebelumnya, sehingga dapat dihindari overfitting. Data training digunakan untuk melatih model, sedangkan data test digunakan untuk mengukur kinerja model. Dalam hal ini, kita dapat memastikan bahwa model yang dibuat memiliki kinerja yang baik pada data yang belum pernah dilihat sebelumnya, sehingga dapat digunakan untuk memprediksi data baru dengan akurasi yang lebih tinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fddc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe34ab",
   "metadata": {},
   "source": [
    "Code tersebut digunakan untuk membagi dataset menjadi training set dan test set dengan menggunakan kelas train_test_split dari library sklearn.model_selection. Variabel x dan y merupakan data yang ingin dibagi. Parameter test_size menunjukkan proporsi data yang ingin dialokasikan sebagai test set. Pada contoh tersebut, proporsi test set adalah 20% dari total data. Parameter random_state digunakan untuk menghasilkan hasil yang konsisten ketika kode dijalankan ulang dengan parameter yang sama. Variabel x_train, x_test, y_train, dan y_test akan berisi data training dan test set yang telah terbagi secara acak dari dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fab57",
   "metadata": {},
   "source": [
    "Cetak beberapa variable data yang telah dilakukan pembagian dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2501657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 1.80000000e+01\n",
      "  2.35100000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 0.00000000e+00 1.85000000e+01\n",
      "  2.62200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.90000000e+01\n",
      "  2.15200000e+03]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.90000000e+01\n",
      "  2.32200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.85000000e+01\n",
      "  2.36200000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.90000000e+01\n",
      "  2.38055556e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.80000000e+01\n",
      "  2.53100000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.90000000e+01\n",
      "  2.38055556e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d01c48c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.800e+01 2.321e+03]\n",
      " [0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.800e+01 2.312e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.850e+01 2.452e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10a2bda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92694b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f404d1",
   "metadata": {},
   "source": [
    "# 6. Melakukan Feature Scaling\n",
    "Feature Scaling digunakan untuk menormalkan variabel-variabel input (fitur) ke dalam rentang yang sama. Teknik ini penting dilakukan terutama pada algoritma-algoritma yang menghitung jarak atau memiliki skala yang sensitif terhadap perbedaan skala antar fitur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c22b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
    "x_test[:, 3:] = sc.transform(x_test[:, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b3c33",
   "metadata": {},
   "source": [
    "Kode tersebut mengimport kelas StandardScaler dari library sklearn.preprocessing untuk melakukan normalisasi data. Data pada kolom ke-3 dan setelahnya pada x_train dan x_test akan di-normalisasi dengan menggunakan StandardScaler.fit_transform() pada x_train dan StandardScaler.transform() pada x_test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04127d8e",
   "metadata": {},
   "source": [
    "Cetak hasil data yang telah dilakukan Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dc8cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.         -0.37796447 -0.37796447\n",
      "  -0.37796447 -0.37796447  2.64575131 -0.37796447 -0.37796447 -1.50755672\n",
      "  -0.27956016]\n",
      " [ 0.          0.          0.          0.         -0.37796447 -0.37796447\n",
      "  -0.37796447 -0.37796447 -0.37796447  2.64575131 -0.37796447 -0.30151134\n",
      "   1.78821006]\n",
      " [ 0.          0.          0.          0.         -0.37796447  2.64575131\n",
      "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.90453403\n",
      "  -1.79795969]\n",
      " [ 1.          0.          0.          0.         -0.37796447 -0.37796447\n",
      "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.90453403\n",
      "  -0.50083446]\n",
      " [ 0.          0.          0.          0.         -0.37796447 -0.37796447\n",
      "   2.64575131 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.30151134\n",
      "  -0.19562853]\n",
      " [ 0.          0.          0.          0.         -0.37796447 -0.37796447\n",
      "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  2.64575131  0.90453403\n",
      "  -0.05404688]\n",
      " [ 0.          0.          0.          0.         -0.37796447 -0.37796447\n",
      "  -0.37796447  2.64575131 -0.37796447 -0.37796447 -0.37796447 -1.50755672\n",
      "   1.09386655]\n",
      " [ 0.          0.          0.          0.          2.64575131 -0.37796447\n",
      "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.90453403\n",
      "  -0.05404688]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f88f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.          0.          0.         -0.37796447 -0.37796447\n",
      "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -1.50755672\n",
      "  -0.50846461]\n",
      " [ 0.          0.          1.          0.         -0.37796447 -0.37796447\n",
      "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -1.50755672\n",
      "  -0.57713595]\n",
      " [ 0.          0.          0.          1.         -0.37796447 -0.37796447\n",
      "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.30151134\n",
      "   0.49108483]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
